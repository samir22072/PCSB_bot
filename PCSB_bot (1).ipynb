{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PCSB_bot.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QsFdKtfUm3U2",
        "outputId": "e0515464-84e7-4a3e-cf34-f7dbc9d3ac97"
      },
      "source": [
        "!pip install rasa==1.10.3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasa==1.10.3\n",
            "  Downloading rasa-1.10.3-py3-none-any.whl (510 kB)\n",
            "\u001b[K     |████████████████████████████████| 510 kB 5.4 MB/s \n",
            "\u001b[?25hCollecting apscheduler<3.7,>=3.6\n",
            "  Downloading APScheduler-3.6.3-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 6.1 MB/s \n",
            "\u001b[?25hCollecting attrs<19.4,>=19.3\n",
            "  Downloading attrs-19.3.0-py2.py3-none-any.whl (39 kB)\n",
            "Collecting fbmessenger<6.1.0,>=6.0.0\n",
            "  Downloading fbmessenger-6.0.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting rocketchat_API<1.4.0,>=0.6.31\n",
            "  Downloading rocketchat_API-1.3.1-py3-none-any.whl (9.6 kB)\n",
            "Collecting colorclass<2.3,>=2.2\n",
            "  Downloading colorclass-2.2.0.tar.gz (17 kB)\n",
            "Collecting async_generator<1.11,>=1.10\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Collecting ruamel.yaml<0.17,>=0.16\n",
            "  Downloading ruamel.yaml-0.16.13-py2.py3-none-any.whl (111 kB)\n",
            "\u001b[K     |████████████████████████████████| 111 kB 48.8 MB/s \n",
            "\u001b[?25hCollecting aiohttp<3.7,>=3.6\n",
            "  Downloading aiohttp-3.6.3-cp37-cp37m-manylinux1_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 37.6 MB/s \n",
            "\u001b[?25hCollecting prompt-toolkit<3.0,>=2.0\n",
            "  Downloading prompt_toolkit-2.0.10-py3-none-any.whl (340 kB)\n",
            "\u001b[K     |████████████████████████████████| 340 kB 47.4 MB/s \n",
            "\u001b[?25hCollecting multidict<5.0,>=4.6\n",
            "  Downloading multidict-4.7.6-cp37-cp37m-manylinux1_x86_64.whl (149 kB)\n",
            "\u001b[K     |████████████████████████████████| 149 kB 53.2 MB/s \n",
            "\u001b[?25hCollecting pykwalify<1.8.0,>=1.7.0\n",
            "  Downloading pykwalify-1.7.0-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 5.6 MB/s \n",
            "\u001b[?25hCollecting sklearn-crfsuite<0.4,>=0.3\n",
            "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
            "Collecting tensorflow<2.2,>=2.1\n",
            "  Downloading tensorflow-2.1.4-cp37-cp37m-manylinux2010_x86_64.whl (422.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 422.0 MB 33 kB/s \n",
            "\u001b[?25hCollecting pymongo[srv,tls]<3.9.0,>=3.8.0\n",
            "  Downloading pymongo-3.8.0-cp37-cp37m-manylinux1_x86_64.whl (417 kB)\n",
            "\u001b[K     |████████████████████████████████| 417 kB 45.4 MB/s \n",
            "\u001b[?25hCollecting twilio<6.27,>=6.26\n",
            "  Downloading twilio-6.26.3-py2.py3-none-any.whl (979 kB)\n",
            "\u001b[K     |████████████████████████████████| 979 kB 43.7 MB/s \n",
            "\u001b[?25hCollecting pytz<2020.0,>=2019.1\n",
            "  Downloading pytz-2019.3-py2.py3-none-any.whl (509 kB)\n",
            "\u001b[K     |████████████████████████████████| 509 kB 41.9 MB/s \n",
            "\u001b[?25hCollecting python-engineio<3.13,>=3.11\n",
            "  Downloading python_engineio-3.12.1-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle<1.4,>=1.2 in /usr/local/lib/python3.7/dist-packages (from rasa==1.10.3) (1.3.0)\n",
            "Collecting terminaltables<3.2.0,>=3.1.0\n",
            "  Downloading terminaltables-3.1.0.tar.gz (12 kB)\n",
            "Collecting packaging<21.0,>=20.0\n",
            "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting coloredlogs<11.0,>=10.0\n",
            "  Downloading coloredlogs-10.0-py2.py3-none-any.whl (47 kB)\n",
            "\u001b[K     |████████████████████████████████| 47 kB 4.5 MB/s \n",
            "\u001b[?25hCollecting tensorflow_hub<0.9,>=0.7\n",
            "  Downloading tensorflow_hub-0.8.0-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 10.4 MB/s \n",
            "\u001b[?25hCollecting jsonpickle<1.5,>=1.3\n",
            "  Downloading jsonpickle-1.4.2-py2.py3-none-any.whl (36 kB)\n",
            "Collecting kafka-python<2.0,>=1.4\n",
            "  Downloading kafka_python-1.4.7-py2.py3-none-any.whl (266 kB)\n",
            "\u001b[K     |████████████████████████████████| 266 kB 41.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3.0,>=2.23 in /usr/local/lib/python3.7/dist-packages (from rasa==1.10.3) (2.23.0)\n",
            "Requirement already satisfied: oauth2client==4.1.3 in /usr/local/lib/python3.7/dist-packages (from rasa==1.10.3) (4.1.3)\n",
            "Collecting tensorflow-estimator==2.1.0\n",
            "  Downloading tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 33.5 MB/s \n",
            "\u001b[?25hCollecting SQLAlchemy<1.4.0,>=1.3.3\n",
            "  Downloading SQLAlchemy-1.3.24-cp37-cp37m-manylinux2010_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 39.8 MB/s \n",
            "\u001b[?25hCollecting python-telegram-bot<13.0,>=11.1\n",
            "  Downloading python_telegram_bot-12.8-py2.py3-none-any.whl (375 kB)\n",
            "\u001b[K     |████████████████████████████████| 375 kB 46.3 MB/s \n",
            "\u001b[?25hCollecting slackclient<3.0.0,>=2.0.0\n",
            "  Downloading slackclient-2.9.3-py2.py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 6.0 MB/s \n",
            "\u001b[?25hCollecting colorhash<1.1.0,>=1.0.2\n",
            "  Downloading colorhash-1.0.3-py3-none-any.whl (4.0 kB)\n",
            "Requirement already satisfied: scikit-learn<0.23,>=0.22 in /usr/local/lib/python3.7/dist-packages (from rasa==1.10.3) (0.22.2.post1)\n",
            "Collecting pydot<1.5,>=1.4\n",
            "  Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
            "Collecting rasa-sdk<2.0.0,>=1.10.0\n",
            "  Downloading rasa_sdk-1.10.3-py3-none-any.whl (39 kB)\n",
            "Collecting absl-py<0.10,>=0.9\n",
            "  Downloading absl-py-0.9.0.tar.gz (104 kB)\n",
            "\u001b[K     |████████████████████████████████| 104 kB 51.3 MB/s \n",
            "\u001b[?25hCollecting psycopg2-binary<2.9.0,>=2.8.2\n",
            "  Downloading psycopg2_binary-2.8.6-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 33.3 MB/s \n",
            "\u001b[?25hCollecting questionary<1.6.0,>=1.5.1\n",
            "  Downloading questionary-1.5.2-py3-none-any.whl (26 kB)\n",
            "Collecting sanic-cors<0.11.0,>=0.10.0b1\n",
            "  Downloading Sanic_Cors-0.10.0.post3-py2.py3-none-any.whl (17 kB)\n",
            "Collecting tensorflow-addons<0.8.0,>=0.7.1\n",
            "  Downloading tensorflow_addons-0.7.1-cp37-cp37m-manylinux2010_x86_64.whl (990 kB)\n",
            "\u001b[K     |████████████████████████████████| 990 kB 37.5 MB/s \n",
            "\u001b[?25hCollecting boto3<2.0,>=1.12\n",
            "  Downloading boto3-1.19.2-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 45.0 MB/s \n",
            "\u001b[?25hCollecting sanic<20.0.0,>=19.12.2\n",
            "  Downloading sanic-19.12.5-py3-none-any.whl (73 kB)\n",
            "\u001b[K     |████████████████████████████████| 73 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy<2.0.0,>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from rasa==1.10.3) (1.4.1)\n",
            "Collecting python-socketio<4.6,>=4.4\n",
            "  Downloading python_socketio-4.5.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 339 kB/s \n",
            "\u001b[?25hCollecting pika<1.2.0,>=1.1.0\n",
            "  Downloading pika-1.1.0-py2.py3-none-any.whl (148 kB)\n",
            "\u001b[K     |████████████████████████████████| 148 kB 46.7 MB/s \n",
            "\u001b[?25hCollecting networkx<2.5.0,>=2.4.0\n",
            "  Downloading networkx-2.4-py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 43.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16 in /usr/local/lib/python3.7/dist-packages (from rasa==1.10.3) (1.19.5)\n",
            "Collecting webexteamssdk<1.4.0,>=1.1.1\n",
            "  Downloading webexteamssdk-1.3.tar.gz (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.9 MB/s \n",
            "\u001b[?25hCollecting gevent<1.6,>=1.4\n",
            "  Downloading gevent-1.5.0-cp37-cp37m-manylinux2010_x86_64.whl (5.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.1 MB 39.8 MB/s \n",
            "\u001b[?25hCollecting redis<4.0,>=3.4\n",
            "  Downloading redis-3.5.3-py2.py3-none-any.whl (72 kB)\n",
            "\u001b[K     |████████████████████████████████| 72 kB 492 kB/s \n",
            "\u001b[?25hCollecting jsonschema<3.3,>=3.2\n",
            "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib<3.3,>=3.1 in /usr/local/lib/python3.7/dist-packages (from rasa==1.10.3) (3.2.2)\n",
            "Collecting tqdm<4.46,>=4.31\n",
            "  Downloading tqdm-4.45.0-py2.py3-none-any.whl (60 kB)\n",
            "\u001b[K     |████████████████████████████████| 60 kB 7.0 MB/s \n",
            "\u001b[?25hCollecting tensorflow-probability<0.10,>=0.7\n",
            "  Downloading tensorflow_probability-0.9.0-py2.py3-none-any.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 26.8 MB/s \n",
            "\u001b[?25hCollecting sanic-jwt<1.5.0,>=1.3.2\n",
            "  Downloading sanic-jwt-1.4.1.tar.gz (19 kB)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from rasa==1.10.3) (57.4.0)\n",
            "Collecting PyJWT<1.8,>=1.7\n",
            "  Downloading PyJWT-1.7.1-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: python-dateutil<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from rasa==1.10.3) (2.8.2)\n",
            "Collecting ujson<3.0,>=1.35\n",
            "  Downloading ujson-2.0.3-cp37-cp37m-manylinux1_x86_64.whl (174 kB)\n",
            "\u001b[K     |████████████████████████████████| 174 kB 38.4 MB/s \n",
            "\u001b[?25hCollecting mattermostwrapper<2.3,>=2.2\n",
            "  Downloading mattermostwrapper-2.2.tar.gz (2.5 kB)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client==4.1.3->rasa==1.10.3) (4.7.2)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from oauth2client==4.1.3->rasa==1.10.3) (0.17.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client==4.1.3->rasa==1.10.3) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client==4.1.3->rasa==1.10.3) (0.4.8)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from oauth2client==4.1.3->rasa==1.10.3) (1.15.0)\n",
            "Requirement already satisfied: chardet<4.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<3.7,>=3.6->rasa==1.10.3) (3.0.4)\n",
            "Collecting yarl<1.6.0,>=1.0\n",
            "  Downloading yarl-1.5.1-cp37-cp37m-manylinux1_x86_64.whl (258 kB)\n",
            "\u001b[K     |████████████████████████████████| 258 kB 50.4 MB/s \n",
            "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
            "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.7/dist-packages (from apscheduler<3.7,>=3.6->rasa==1.10.3) (1.5.1)\n",
            "Collecting botocore<1.23.0,>=1.22.2\n",
            "  Downloading botocore-1.22.2-py3-none-any.whl (8.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.0 MB 26.1 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.6 MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 47.1 MB/s \n",
            "\u001b[?25hCollecting humanfriendly>=4.7\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: greenlet>=0.4.14 in /usr/local/lib/python3.7/dist-packages (from gevent<1.6,>=1.4->rasa==1.10.3) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonpickle<1.5,>=1.3->rasa==1.10.3) (4.8.1)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema<3.3,>=3.2->rasa==1.10.3) (0.18.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib<3.3,>=3.1->rasa==1.10.3) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<3.3,>=3.1->rasa==1.10.3) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<3.3,>=3.1->rasa==1.10.3) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx<2.5.0,>=2.4.0->rasa==1.10.3) (4.4.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<3.0,>=2.0->rasa==1.10.3) (0.2.5)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.7/dist-packages (from pykwalify<1.8.0,>=1.7.0->rasa==1.10.3) (3.13)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from pykwalify<1.8.0,>=1.7.0->rasa==1.10.3) (0.6.2)\n",
            "Collecting dnspython<2.0.0,>=1.13.0\n",
            "  Downloading dnspython-1.16.0-py2.py3-none-any.whl (188 kB)\n",
            "\u001b[K     |████████████████████████████████| 188 kB 45.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot<13.0,>=11.1->rasa==1.10.3) (5.1.1)\n",
            "Collecting cryptography\n",
            "  Downloading cryptography-35.0.0-cp36-abi3-manylinux_2_24_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 47.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot<13.0,>=11.1->rasa==1.10.3) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.23->rasa==1.10.3) (2.10)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 23.3 MB/s \n",
            "\u001b[?25hCollecting ruamel.yaml.clib>=0.1.2\n",
            "  Downloading ruamel.yaml.clib-0.2.6-cp37-cp37m-manylinux1_x86_64.whl (546 kB)\n",
            "\u001b[K     |████████████████████████████████| 546 kB 43.2 MB/s \n",
            "\u001b[?25hCollecting websockets<9.0,>=7.0\n",
            "  Downloading websockets-8.1-cp37-cp37m-manylinux2010_x86_64.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.3 MB/s \n",
            "\u001b[?25hCollecting httpx==0.9.3\n",
            "  Downloading httpx-0.9.3-py2.py3-none-any.whl (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 3.4 MB/s \n",
            "\u001b[?25hCollecting httptools>=0.0.10\n",
            "  Downloading httptools-0.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (402 kB)\n",
            "\u001b[K     |████████████████████████████████| 402 kB 29.7 MB/s \n",
            "\u001b[?25hCollecting aiofiles>=0.3.0\n",
            "  Downloading aiofiles-0.7.0-py3-none-any.whl (13 kB)\n",
            "Collecting uvloop<0.15.0,>=0.5.3\n",
            "  Downloading uvloop-0.14.0-cp37-cp37m-manylinux2010_x86_64.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 33.2 MB/s \n",
            "\u001b[?25hCollecting sanic<20.0.0,>=19.12.2\n",
            "  Downloading sanic-19.12.4-py3-none-any.whl (73 kB)\n",
            "\u001b[K     |████████████████████████████████| 73 kB 1.5 MB/s \n",
            "\u001b[?25hCollecting uvloop>=0.5.3\n",
            "  Downloading uvloop-0.16.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 33.1 MB/s \n",
            "\u001b[?25hCollecting sanic<20.0.0,>=19.12.2\n",
            "  Downloading sanic-19.12.3-py3-none-any.whl (72 kB)\n",
            "\u001b[K     |████████████████████████████████| 72 kB 1.2 MB/s \n",
            "\u001b[?25h  Downloading sanic-19.12.2-py3-none-any.whl (72 kB)\n",
            "\u001b[K     |████████████████████████████████| 72 kB 900 kB/s \n",
            "\u001b[?25hCollecting h11==0.8.*\n",
            "  Downloading h11-0.8.1-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting sniffio==1.*\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting hstspreload\n",
            "  Downloading hstspreload-2021.10.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 37.4 MB/s \n",
            "\u001b[?25hCollecting rfc3986<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting h2==3.*\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 3.6 MB/s \n",
            "\u001b[?25hCollecting hpack<4,>=3.0\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Collecting hyperframe<6,>=5.2.0\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting sanic-plugins-framework>=0.9.0\n",
            "  Downloading Sanic_Plugins_Framework-0.9.5-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.23,>=0.22->rasa==1.10.3) (1.0.1)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "  Downloading python_crfsuite-0.9.7-cp37-cp37m-manylinux1_x86_64.whl (743 kB)\n",
            "\u001b[K     |████████████████████████████████| 743 kB 27.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite<0.4,>=0.3->rasa==1.10.3) (0.8.9)\n",
            "Collecting numpy<2.0,>=1.16\n",
            "  Downloading numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.2,>=2.1->rasa==1.10.3) (0.2.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.2,>=2.1->rasa==1.10.3) (0.8.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.2,>=2.1->rasa==1.10.3) (3.3.0)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "  Downloading tensorboard-2.1.1-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 32.4 MB/s \n",
            "\u001b[?25hCollecting h5py<=2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 37.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.2,>=2.1->rasa==1.10.3) (3.17.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.2,>=2.1->rasa==1.10.3) (1.1.0)\n",
            "Collecting keras-preprocessing==1.1.0\n",
            "  Downloading Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 581 kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.2,>=2.1->rasa==1.10.3) (0.37.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.2,>=2.1->rasa==1.10.3) (1.41.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.2,>=2.1->rasa==1.10.3) (1.12.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1->rasa==1.10.3) (0.4.6)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1->rasa==1.10.3) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1->rasa==1.10.3) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1->rasa==1.10.3) (1.0.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1->rasa==1.10.3) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1->rasa==1.10.3) (1.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1->rasa==1.10.3) (3.1.1)\n",
            "Requirement already satisfied: pysocks in /usr/local/lib/python3.7/dist-packages (from twilio<6.27,>=6.26->rasa==1.10.3) (1.7.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from webexteamssdk<1.4.0,>=1.1.1->rasa==1.10.3) (0.16.0)\n",
            "Collecting requests-toolbelt\n",
            "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from yarl<1.6.0,>=1.0->aiohttp<3.7,>=3.6->rasa==1.10.3) (3.7.4.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography->python-telegram-bot<13.0,>=11.1->rasa==1.10.3) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography->python-telegram-bot<13.0,>=11.1->rasa==1.10.3) (2.20)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->jsonpickle<1.5,>=1.3->rasa==1.10.3) (3.6.0)\n",
            "Building wheels for collected packages: absl-py, colorclass, mattermostwrapper, sanic-jwt, gast, terminaltables, webexteamssdk\n",
            "  Building wheel for absl-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for absl-py: filename=absl_py-0.9.0-py3-none-any.whl size=121940 sha256=dc5047f5b5704ff43446726fba8287f4a564da72fced732a491dc71b820ffc02\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/af/1a/498a24d0730ef484019e007bb9e8cef3ac00311a672c049a3e\n",
            "  Building wheel for colorclass (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colorclass: filename=colorclass-2.2.0-py3-none-any.whl size=19395 sha256=6e9cb713574d229b90ba3388a5446c8d3b5beeb006561df60d5605be95b042dd\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/96/67/750617a6039bb687b993830c5852beba03d777e2d5b0b06938\n",
            "  Building wheel for mattermostwrapper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mattermostwrapper: filename=mattermostwrapper-2.2-py3-none-any.whl size=2462 sha256=17e1f196f6338dcf6c3965009411433312f16aeda8637de432f8129b5bf44e73\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/70/77/6c3f3c9a6f096f765d0767b21e73598d66c3b79cb7b09b62ad\n",
            "  Building wheel for sanic-jwt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sanic-jwt: filename=sanic_jwt-1.4.1-py3-none-any.whl size=21614 sha256=43cf2963a27ebfc9f6f3ecaefd48cc16937a4b1c05015e1f200be91d2cd893b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/df/b1/f72efce63fe6e26b2bae666e1cae88c68c38d718dafb9183b0\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=0d7624ed423a6f2f49a05e401766897ce15a902c005115f587a3a08cbd998e4e\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-py3-none-any.whl size=15354 sha256=56cccbbf9d8ae3a652f637c118baceb00f9e9198190c16291034851a240c324a\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/ad/c8/2d98360791161cd3db6daf6b5e730f34021fc9367d5879f497\n",
            "  Building wheel for webexteamssdk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for webexteamssdk: filename=webexteamssdk-1.3-py3-none-any.whl size=99581 sha256=151d2147ca6f46a6c5de47d505f62e1da06385e08ee6c5a7f562913fd3fcd4c9\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/88/4d/7fe6eec20e0658e8ad6edd9969d27114280780d7f4ef42e436\n",
            "Successfully built absl-py colorclass mattermostwrapper sanic-jwt gast terminaltables webexteamssdk\n",
            "Installing collected packages: urllib3, hyperframe, hpack, sniffio, rfc3986, hstspreload, h2, h11, websockets, uvloop, ujson, numpy, multidict, httpx, httptools, aiofiles, sanic, jmespath, h5py, absl-py, yarl, tensorflow-estimator, tensorboard, sanic-plugins-framework, pytz, keras-preprocessing, keras-applications, humanfriendly, gast, botocore, attrs, async-timeout, tqdm, tensorflow, sanic-cors, s3transfer, ruamel.yaml.clib, requests-toolbelt, python-engineio, python-crfsuite, pymongo, PyJWT, prompt-toolkit, dnspython, cryptography, coloredlogs, aiohttp, webexteamssdk, twilio, terminaltables, tensorflow-probability, tensorflow-hub, tensorflow-addons, SQLAlchemy, slackclient, sklearn-crfsuite, sanic-jwt, ruamel.yaml, rocketchat-API, redis, rasa-sdk, questionary, python-telegram-bot, python-socketio, pykwalify, pydot, psycopg2-binary, pika, packaging, networkx, mattermostwrapper, kafka-python, jsonschema, jsonpickle, gevent, fbmessenger, colorhash, colorclass, boto3, async-generator, apscheduler, rasa\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 0.12.0\n",
            "    Uninstalling absl-py-0.12.0:\n",
            "      Successfully uninstalled absl-py-0.12.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.6.0\n",
            "    Uninstalling tensorflow-estimator-2.6.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.6.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.6.0\n",
            "    Uninstalling tensorboard-2.6.0:\n",
            "      Successfully uninstalled tensorboard-2.6.0\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2018.9\n",
            "    Uninstalling pytz-2018.9:\n",
            "      Successfully uninstalled pytz-2018.9\n",
            "  Attempting uninstall: keras-preprocessing\n",
            "    Found existing installation: Keras-Preprocessing 1.1.2\n",
            "    Uninstalling Keras-Preprocessing-1.1.2:\n",
            "      Successfully uninstalled Keras-Preprocessing-1.1.2\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 21.2.0\n",
            "    Uninstalling attrs-21.2.0:\n",
            "      Successfully uninstalled attrs-21.2.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.62.3\n",
            "    Uninstalling tqdm-4.62.3:\n",
            "      Successfully uninstalled tqdm-4.62.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.6.0\n",
            "    Uninstalling tensorflow-2.6.0:\n",
            "      Successfully uninstalled tensorflow-2.6.0\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 3.12.0\n",
            "    Uninstalling pymongo-3.12.0:\n",
            "      Successfully uninstalled pymongo-3.12.0\n",
            "  Attempting uninstall: prompt-toolkit\n",
            "    Found existing installation: prompt-toolkit 1.0.18\n",
            "    Uninstalling prompt-toolkit-1.0.18:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.18\n",
            "  Attempting uninstall: tensorflow-probability\n",
            "    Found existing installation: tensorflow-probability 0.14.1\n",
            "    Uninstalling tensorflow-probability-0.14.1:\n",
            "      Successfully uninstalled tensorflow-probability-0.14.1\n",
            "  Attempting uninstall: tensorflow-hub\n",
            "    Found existing installation: tensorflow-hub 0.12.0\n",
            "    Uninstalling tensorflow-hub-0.12.0:\n",
            "      Successfully uninstalled tensorflow-hub-0.12.0\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 1.4.25\n",
            "    Uninstalling SQLAlchemy-1.4.25:\n",
            "      Successfully uninstalled SQLAlchemy-1.4.25\n",
            "  Attempting uninstall: pydot\n",
            "    Found existing installation: pydot 1.3.0\n",
            "    Uninstalling pydot-1.3.0:\n",
            "      Successfully uninstalled pydot-1.3.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 21.0\n",
            "    Uninstalling packaging-21.0:\n",
            "      Successfully uninstalled packaging-21.0\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 2.6.3\n",
            "    Uninstalling networkx-2.6.3:\n",
            "      Successfully uninstalled networkx-2.6.3\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 2.6.0\n",
            "    Uninstalling jsonschema-2.6.0:\n",
            "      Successfully uninstalled jsonschema-2.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "panel 0.12.1 requires tqdm>=4.48.0, but you have tqdm 4.45.0 which is incompatible.\n",
            "nbclient 0.5.4 requires jupyter-client>=6.1.5, but you have jupyter-client 5.3.5 which is incompatible.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 2.0.10 which is incompatible.\n",
            "ipython 5.5.0 requires prompt-toolkit<2.0.0,>=1.0.4, but you have prompt-toolkit 2.0.10 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed PyJWT-1.7.1 SQLAlchemy-1.3.24 absl-py-0.9.0 aiofiles-0.7.0 aiohttp-3.6.3 apscheduler-3.6.3 async-generator-1.10 async-timeout-3.0.1 attrs-19.3.0 boto3-1.19.2 botocore-1.22.2 colorclass-2.2.0 coloredlogs-10.0 colorhash-1.0.3 cryptography-35.0.0 dnspython-1.16.0 fbmessenger-6.0.0 gast-0.2.2 gevent-1.5.0 h11-0.8.1 h2-3.2.0 h5py-2.10.0 hpack-3.0.0 hstspreload-2021.10.1 httptools-0.3.0 httpx-0.9.3 humanfriendly-10.0 hyperframe-5.2.0 jmespath-0.10.0 jsonpickle-1.4.2 jsonschema-3.2.0 kafka-python-1.4.7 keras-applications-1.0.8 keras-preprocessing-1.1.0 mattermostwrapper-2.2 multidict-4.7.6 networkx-2.4 numpy-1.18.5 packaging-20.9 pika-1.1.0 prompt-toolkit-2.0.10 psycopg2-binary-2.8.6 pydot-1.4.2 pykwalify-1.7.0 pymongo-3.8.0 python-crfsuite-0.9.7 python-engineio-3.12.1 python-socketio-4.5.1 python-telegram-bot-12.8 pytz-2019.3 questionary-1.5.2 rasa-1.10.3 rasa-sdk-1.10.3 redis-3.5.3 requests-toolbelt-0.9.1 rfc3986-1.5.0 rocketchat-API-1.3.1 ruamel.yaml-0.16.13 ruamel.yaml.clib-0.2.6 s3transfer-0.5.0 sanic-19.12.2 sanic-cors-0.10.0.post3 sanic-jwt-1.4.1 sanic-plugins-framework-0.9.5 sklearn-crfsuite-0.3.6 slackclient-2.9.3 sniffio-1.2.0 tensorboard-2.1.1 tensorflow-2.1.4 tensorflow-addons-0.7.1 tensorflow-estimator-2.1.0 tensorflow-hub-0.8.0 tensorflow-probability-0.9.0 terminaltables-3.1.0 tqdm-4.45.0 twilio-6.26.3 ujson-2.0.3 urllib3-1.25.11 uvloop-0.16.0 webexteamssdk-1.3 websockets-8.1 yarl-1.5.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "prompt_toolkit",
                  "pytz"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLT-CKwrnqJF",
        "outputId": "42d6578e-7525-4e89-ee1f-3accf822dd79"
      },
      "source": [
        "!python -m spacy download en"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.45.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.25.11)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAw_bEDVnyXw",
        "outputId": "695a53c9-0415-48f5-fac6-e80cf24bc2a0"
      },
      "source": [
        "!pip install nest_asyncio==1.3.3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nest_asyncio==1.3.3\n",
            "  Downloading nest_asyncio-1.3.3-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: nest-asyncio\n",
            "  Attempting uninstall: nest-asyncio\n",
            "    Found existing installation: nest-asyncio 1.5.1\n",
            "    Uninstalling nest-asyncio-1.5.1:\n",
            "      Successfully uninstalled nest-asyncio-1.5.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "nbclient 0.5.4 requires jupyter-client>=6.1.5, but you have jupyter-client 5.3.5 which is incompatible.\u001b[0m\n",
            "Successfully installed nest-asyncio-1.3.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhDKuVU7n4i3",
        "outputId": "006e49ff-fba3-485f-9f79-e57424bf7e8b"
      },
      "source": [
        "import os\n",
        "import rasa\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "print(\"event loop ready\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "event loop ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNpkrCGboB_K"
      },
      "source": [
        "from rasa.cli.scaffold import create_initial_project"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qFjzbJGoGKh"
      },
      "source": [
        "project = 'test_project'\n",
        "create_initial_project(project)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gp4szZ_yoS2J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81d5f08f-ce21-4950-830e-2d05679b4344"
      },
      "source": [
        "os.chdir(project)\n",
        "print(os.listdir(\".\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tests', 'actions.py', 'data', 'endpoints.yml', '__pycache__', 'config.yml', 'credentials.yml', 'domain.yml', '__init__.py']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXfDsNA0oWu5",
        "outputId": "bbaa5e1f-ceca-4bc6-cbfa-bd196503f38c"
      },
      "source": [
        "config = \"config.yml\"\n",
        "training_files = \"data/\"\n",
        "domain = 'domain.yml'\n",
        "output = 'models/'\n",
        "print(config,training_files,domain,output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.yml data/ domain.yml models/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c70bpfiuob9m",
        "outputId": "c5c52c49-a21a-40ca-8c9c-69e511003cab"
      },
      "source": [
        "model_path = rasa.train(domain, config, [training_files], output)\n",
        "print(model_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94mTraining Core model...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processed Story Blocks: 100%|██████████| 5/5 [00:00<00:00, 160.95it/s, # trackers=1]\n",
            "Processed Story Blocks: 100%|██████████| 5/5 [00:00<00:00, 349.99it/s, # trackers=5]\n",
            "Processed Story Blocks: 100%|██████████| 5/5 [00:00<00:00, 121.74it/s, # trackers=20]\n",
            "Processed Story Blocks: 100%|██████████| 5/5 [00:00<00:00, 91.28it/s, # trackers=24]\n",
            "Processed trackers: 100%|██████████| 5/5 [00:00<00:00, 88.13it/s, # actions=16]\n",
            "Processed actions: 16it [00:00, 557.48it/s, # examples=16]\n",
            "Processed trackers: 100%|██████████| 231/231 [00:07<00:00, 29.57it/s, # actions=126]\n",
            "Epochs:   0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/rasa/utils/tensorflow/model_data.py:386: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  final_data[k].append(np.concatenate(np.array(v)))\n",
            "Epochs: 100%|██████████| 100/100 [00:18<00:00,  5.37it/s, t_loss=0.084, loss=0.011, acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94mCore model training completed.\u001b[0m\n",
            "\u001b[94mTraining NLU model...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[93m/usr/local/lib/python3.7/dist-packages/rasa/utils/common.py:363: UserWarning: You specified 'DIET' to train entities, but no entities are present in the training data. Skip training of entities.\n",
            "Epochs:   0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/rasa/utils/tensorflow/model_data.py:386: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  final_data[k].append(np.concatenate(np.array(v)))\n",
            "Epochs: 100%|██████████| 100/100 [00:08<00:00, 11.34it/s, t_loss=1.444, i_loss=0.069, i_acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94mNLU model training completed.\u001b[0m\n",
            "\u001b[92mYour Rasa model is trained and saved at '/content/test_project/models/20211025-132054.tar.gz'.\u001b[0m\n",
            "models/20211025-132054.tar.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3EPhiaVo0bm",
        "outputId": "854f256a-f11c-405c-d58b-1e373b2389b4"
      },
      "source": [
        "from rasa.jupyter import chat\n",
        "\n",
        "endpoints = 'endpoints.yml'\n",
        "\n",
        "chat(model_path, endpoints)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your bot is ready to talk! Type your messages here or send '/stop'.\n",
            "hi\n",
            "\u001b[92mHey! How are you?\u001b[0m\n",
            "fine\n",
            "\u001b[92mBye\u001b[0m\n",
            "/stop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9B7Fa6d-o8xe",
        "outputId": "6ed690ef-3cf6-4758-dc9d-71c68407a5ba"
      },
      "source": [
        "%%writefile data/nlu.md\n",
        "\n",
        "##intent:PCSB_sig\n",
        "- What are Special interest groups\n",
        "- What sigs does the club conduct\n",
        "- What sig taken \n",
        "- sig\n",
        "\n",
        "##intent:PCSB_history\n",
        "- Tell me about PCSB\n",
        "- What is the history of PCSB\n",
        "- History of PICT CSI\n",
        "- Information about PCSB\n",
        "\n",
        "##intent:Xenia_ninja\n",
        "- What is ninja Coding?\n",
        "- what is the premise of ninjacoding?\n",
        "- what is ninjacoding all about?\n",
        "- explain ninja coding to me.\n",
        "- elaborate about ninja coding\n",
        "\n",
        "##intent:Xenia_design\n",
        "- What is design maestro\n",
        "- elaborate about design maestro?\n",
        "- explain design maestro\n",
        "- what is designmaestro about?\n",
        "\n",
        "##intent:Xenia_minecraft\n",
        "- What is minecraft build battles?\n",
        "- what is the minecraft event?\n",
        "- elaborate about minecraft build battles.\n",
        "- explain minecraft build battles?\n",
        "\n",
        "##intent:Xenia_xenathon\n",
        "- What is xenathon about?\n",
        "- explain Xenathon to me.\n",
        "- What is the premise of Xenathon?\n",
        "- Elaborate about xenathon.\n",
        "\n",
        "##intent:Xenia_Circuitron\n",
        "- What is circuitron about?\n",
        "- Explain circuitron to me.\n",
        "- elaborate about circuitron.\n",
        "- What is the premise of circuitron?\n",
        "\n",
        "##intent:Xenia_Innoveiren\n",
        "- What is innoveiren about?\n",
        "- expalin innoveiren to me.\n",
        "- elaborate on innoveiren.\n",
        "- What is innoveiren event?\n",
        "\n",
        "##intent:Xenia_Data\n",
        "- What is Data cup?\n",
        "- explain about Datacup\n",
        "- elaborate on Datacup\n",
        "- what is the premise of data cup?\n",
        "\n",
        "\n",
        "##intent:Xenia_Campus\n",
        "- What is campus to corporate?\n",
        "- what is campus to corporate event about?\n",
        "- Explain about campus to corporate.\n",
        "- elaborate on campus to corporate \n",
        "\n",
        "##intent:Xenia_Snaphunt\n",
        "- What is Snaphunt?\n",
        "- What is the Snaphunt event about?\n",
        "- Explain about Snaphunt event.\n",
        "- Elaborate on Snaphunt\n",
        "\n",
        "##intent:Xenia_Gab\n",
        "- What is event gift of gab about?\n",
        "- what does gift of gab involve?\n",
        "- elaborate about gift of gab\n",
        "- explain about gift of gab event\n",
        "\n",
        "##intent:Xenia_Game\n",
        "- What is event gamezone about?\n",
        "- what does game zone involve?\n",
        "- elaborate about game zone\n",
        "- explain about gamezone event\n",
        "\n",
        "##intent:Xenia_Dream\n",
        "- What is event dream tema?\n",
        "- what does dream team involve?\n",
        "- elaborate about dream team\n",
        "- explain about dream team event\n",
        "\n",
        "##intent:Xenia_Shark\n",
        "- What is event shark tank about?\n",
        "- what does sharktank involve?\n",
        "- elaborate about shark tank\n",
        "- explain about shark tank event\n",
        "\n",
        "##intent:Xenia_Couch\n",
        "- What is event couch potato about?\n",
        "- what does couch potato involve?\n",
        "- elaborate about couch potato\n",
        "- explain about couch potato event\n",
        "\n",
        "##intent:Xenia_Xenatus\n",
        "- What is event xenatus about?\n",
        "- what does xenatus involve?\n",
        "- elaborate about xenatus\n",
        "- explain about xenatus event\n",
        "\n",
        "##intent:Xenia_codestrike\n",
        "- What is codestrike\n",
        "- Give me the details of codestrike\n",
        "- elaborate about codestrike\n",
        "- explain codestrike to me.\n",
        "\n",
        "##intent:pcsb_Xenia\n",
        "- Tell me something about Xenia.\n",
        "- Tell me about the flagship event.\n",
        "- What is Xenia.\n",
        "- What can I expect from Xenia.\n",
        "\n",
        "## intent:pcsb_events\n",
        "- What are the many events that the club conducts\n",
        "- what things does pcsb do\n",
        "- what is the flagship event of pcsb\n",
        "- what events will i get to participate in\n",
        "- What are the events organized by pcsb\n",
        "- What events are there in pcsb\n",
        "\n",
        "## intent:pcsb_perks\n",
        "- What are the perks of joining the club\n",
        "- What are the perks of joining PCSB\n",
        "- why PCSB\n",
        "- what do i gain by joining the club\n",
        "\n",
        "## intent:greet\n",
        "- hey\n",
        "- hello\n",
        "- hi\n",
        "- good morning\n",
        "- good evening\n",
        "- hey there\n",
        "\n",
        "## intent:goodbye\n",
        "- bye\n",
        "- goodbye\n",
        "- see you around\n",
        "- see you later\n",
        "\n",
        "## intent:affirm\n",
        "- yes\n",
        "- indeed\n",
        "- of course\n",
        "- that sounds good\n",
        "- correct\n",
        "- ok\n",
        "\n",
        "## intent:deny\n",
        "- no\n",
        "- never\n",
        "- I don't think so\n",
        "- don't like that\n",
        "- no way\n",
        "- not really\n",
        "\n",
        "## intent:mood_great\n",
        "- perfect\n",
        "- very good\n",
        "- great\n",
        "- amazing\n",
        "- wonderful\n",
        "- I am feeling very good\n",
        "- I am great\n",
        "- I'm good\n",
        "- I am fine\n",
        "\n",
        "## intent:mood_unhappy\n",
        "- sad\n",
        "- very sad\n",
        "- unhappy\n",
        "- bad\n",
        "- very bad\n",
        "- awful\n",
        "- terrible\n",
        "- not very good\n",
        "- extremely sad\n",
        "- so sad\n",
        "\n",
        "## intent:bot_challenge\n",
        "- are you a bot?\n",
        "- are you a human?\n",
        "- am I talking to a bot?\n",
        "- am I talking to a human?\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting data/nlu.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5JKJSnOpp26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0c779be-db78-4c6b-9c44-87a5f8c74ec3"
      },
      "source": [
        "%%writefile domain.yml\n",
        "\n",
        "intents:\n",
        "  - greet\n",
        "  - goodbye\n",
        "  - affirm\n",
        "  - deny\n",
        "  - mood_great\n",
        "  - mood_unhappy\n",
        "  - bot_challenge\n",
        "  - pcsb_perks\n",
        "  - pcsb_events\n",
        "  - pcsb_Xenia\n",
        "  - Xenia_codestrike\n",
        "  - Xenia_ninja\n",
        "  - Xenia_minecraft\n",
        "  - Xenia_design\n",
        "  - Xenia_xenathon\n",
        "  - Xenia_Circuitron\n",
        "  - Xenia_Data\n",
        "  - Xenia_Innoveiren\n",
        "  - Xenia_Xenatus\n",
        "  - Xenia_Snaphunt\n",
        "  - Xenia_Game\n",
        "  - Xenia_Gab\n",
        "  - Xenia_Shark\n",
        "  - Xenia_Campus\n",
        "  - Xenia_Dream\n",
        "  - Xenia_Couch\n",
        "  - PCSB_history\n",
        "  - PCSB_sig\n",
        "\n",
        "responses:\n",
        "  utter_PCSB_sig:\n",
        "  - text: \"PCSB conducts multiple sigs throughout the year such as c++ and python.\"\n",
        "  \n",
        "  utter_PCSB_history:\n",
        "  - text: \"PICT CSI Student Branch, working under CSI, was established in 2016 to facilitate research, knowlwdge, and career enhancement for the students and inspire and nurture new entrants into the industry.\\nIt provides a platform for technical and non-technical education.\\nOne of our key strengths at PCSB is our rate of growthin a short span of time.\\nWe take pride in that we are one of the best student communities in Pune, still growing exponentially.\\n\"\n",
        "\n",
        "  utter_Xenia_ninja:\n",
        "  - text: \"Ninja coding has two rounds that will test your knowlwdge about competitive programming, debugging skills and reverse coding ability.\"\n",
        "\n",
        "  utter_Xenia_minecraft:\n",
        "  - text: \"Minecraft is a sandbox game where the only limit is your imagination. Students have to build a structure according to the given theme.\"\n",
        "\n",
        "  utter_Xenia_design:\n",
        "  - text: \"In design maestro, participants have to create a wireframe for their website and code the same wireframe into existance.\"\n",
        "\n",
        "  utter_Xenia_xenathon:\n",
        "  - text: \"Participants will have to automate daily life tasks to ease their lives which can be achieved by creation of software bots to complete a task.\"\n",
        "\n",
        "  utter_Xenia_Circuitron:\n",
        "  - text: \"Circuitron is for all who love to create circuits. Participants will be given problem statements on which they will have to create circuits.\"\n",
        "\n",
        "  utter_Xenia_Data:\n",
        "  - text: \"Data cup is a data science competition on Kaggle. It has 2 rounds.\"\n",
        "\n",
        "  utter_Xenia_Innoveiren:\n",
        "  - text: \"Innoveiren is a group event. Participants will have to present their projects along with explaination to Industry experts.\"\n",
        "\n",
        "  utter_Xenia_Xenatus:\n",
        "  - text: \"Xenatus is a general aptitude based event.\"\n",
        "\n",
        "  utter_Xenia_Snaphunt:\n",
        "  - text: \"Snaphunt is a group event in which each team is given a list of tasks.\\nThey have to upload a picture or video according to the requirement of the question.\"\n",
        "\n",
        "  utter_Xenia_Game:\n",
        "  - text: \"Valorant fans, this is an amazing opportunity to show off your gaming skills.\"\n",
        "\n",
        "  utter_Xenia_Gab:\n",
        "  - text: \"The gift of gab is a technical debate competition.\"\n",
        "\n",
        "  utter_Xenia_Shark:\n",
        "  - text: \"If you have an innovative idea, this is your opportunity to work upon the next fortune 500 aiming to change the world.\"\n",
        "\n",
        "  utter_Xenia_Campus:\n",
        "  - text: \"Campus to corporate includes aptitude, group discussion and interview.\"\n",
        "\n",
        "  utter_Xenia_Dream:\n",
        "  - text: \"Grab your IPL crazy team to participate in a quiz and a mock IPL auction.\"\n",
        "\n",
        "  utter_Xenia_Couch:\n",
        "  - text: \"Who will become the next Binge-llionaire? Quiz on popular shows from all around the world.\"\n",
        "\n",
        "  utter_more_info:\n",
        "  - text: \"For for more info visit PCSB [Xenia website](https://pcsbxenia.com/).\"\n",
        "\n",
        "  utter_Xenia_codestrike:\n",
        "  - text: \"Codestrike is a competitive programming contest hosted online.\\nRules:\\n\\t1. Programmers can choose any language of their choice.\\n\\t2. The duration of the event is 2 hours.\\n\\t3. It is an individual event.\"\n",
        "\n",
        "  utter_pcsb_Xenia: \n",
        "  - text: \"Xenia is the annual technical fiesta organized by PCSB.\\nIt includes 8 technical and 8 non technical events.\\n\\tA. Technical events:\\n\\t 1. Codestrike\\n\\t 2. Ninja Coding\\n\\t 3. Design Mastro\\n\\t 4. MineCraft Build Battles\\n\\t 5. Xenathon\\n\\t 6. Circuitron\\n\\t 7. Innoveiren\\n\\t 8. Data Cup\\n\\tB. Non technical events:\\n\\t 1. Campus to Corporate\\n\\t 2. SnapHunt\\n\\t 3. The Gift of Gab\\n\\t 4. Game Zone\\n\\t 5. Dream Team\\n\\t 6. Shark Tank\\n\\t 7. Couch Potato\\n\\t 8. Xenatus\\nDo you want me to elaborate on any of the event?\"\n",
        "\n",
        "  utter_pcsb_events:\n",
        "  - text: \"PCSB conducts numerous events in a year.\\nSome of them are:\\n\\t1. Xenia: The flagship event.\\n\\t2. Special Interest Groups.\\n\\t3. Panel Interviews.\\n\\t4. Domain Introduction.\\nand many more.\"\n",
        "\n",
        "  utter_pcsb_perks:\n",
        "  - text: \"PCSB is one of the most lively and innovative clubs at PICT.\\nThere are numerous perks to joining thr club. You will find a community of like minded, driven individuals\\nwho will give you opportunities and encouragement to acheve more.\\nYou can find people from all domains here such as Web dev, app dev and non technical domains like design and content.\"\n",
        "  \n",
        "  utter_greet:\n",
        "  - text: \"Hey! How are you?\"\n",
        "\n",
        "  utter_cheer_up:\n",
        "  - text: \"Here is something to cheer you up:\"\n",
        "    image: \"https://i.imgur.com/nGF1K8f.jpg\"\n",
        "\n",
        "  utter_did_that_help:\n",
        "  - text: \"Did that help you?\"\n",
        "\n",
        "  utter_happy:\n",
        "  - text: \"Great, carry on!\"\n",
        "\n",
        "  utter_goodbye:\n",
        "  - text: \"Bye\"\n",
        "\n",
        "  utter_iamabot:\n",
        "  - text: \"I am a bot, powered by Rasa.\"\n",
        "\n",
        "session_config:\n",
        "  session_expiration_time: 60\n",
        "  carry_over_slots_to_new_session: true\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting domain.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vTCBRFypwdr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d4d52b6-633a-4b6f-d2b3-af71d1e45362"
      },
      "source": [
        "%%writefile data/stories.md\n",
        "\n",
        "## PCSB Sig\n",
        "* greet\n",
        "  - utter_greet\n",
        "* PCSB_sig\n",
        "  - utter_PCSB_sig\n",
        "* affirm\n",
        "  -utter_happy\n",
        "\n",
        "## PCSB History\n",
        "* greet\n",
        "  - utter_greet\n",
        "* PCSB_history\n",
        "  - utter_PCSB_history\n",
        "* affirm\n",
        "  -utter_happy\n",
        "\n",
        "## Xenia Codestrike\n",
        "* greet\n",
        "  - utter_greet\n",
        "* Xenia_codestrike\n",
        "  - utter_Xenia_codestrike\n",
        "  - utter_more_info\n",
        "* affirm\n",
        "  - utter_happy\n",
        "\n",
        "## Xenia Ninja\n",
        "* greet\n",
        "  - utter_greet\n",
        "* Xenia_ninja\n",
        "  - utter_Xenia_ninja\n",
        "  - utter_more_info\n",
        "* affirm\n",
        "  - utter_happy\n",
        "\n",
        "## Xenia Minecraft\n",
        "* greet\n",
        "  - utter_greet\n",
        "* Xenia_minecraft\n",
        "  - utter_Xenia_minecraft\n",
        "  - utter_more_info\n",
        "* affirm\n",
        "  - utter_happy\n",
        "\n",
        "## Xenia Data\n",
        "* greet\n",
        "  - utter_greet\n",
        "* Xenia_Data\n",
        "  - utter_Xenia_Data\n",
        "  - utter_more_info\n",
        "* affirm\n",
        "  - utter_happy\n",
        "\n",
        "## Xenia Xenathon\n",
        "* greet\n",
        "  - utter_greet\n",
        "* Xenia_xenathon\n",
        "  - utter_Xenia_xenathon\n",
        "  - utter_more_info\n",
        "* affirm\n",
        "  - utter_happy\n",
        "\n",
        "## Xenia Design\n",
        "* greet\n",
        "  - utter_greet\n",
        "* Xenia_design\n",
        "  - utter_Xenia_design\n",
        "  - utter_more_info\n",
        "* affirm\n",
        "  - utter_happy\n",
        "\n",
        "## Xenia Innoveiren\n",
        "* greet\n",
        "  - utter_greet\n",
        "* Xenia_Innoveiren\n",
        "  - utter_Xenia_Innoveiren\n",
        "  - utter_more_info\n",
        "* affirm\n",
        "  - utter_happy\n",
        "\n",
        "## Xenia Circuitron\n",
        "* greet\n",
        "  - utter_greet\n",
        "* Xenia_Circuitron\n",
        "  - utter_Xenia_Circuitron\n",
        "  - utter_more_info\n",
        "* affirm\n",
        "  - utter_happy\n",
        "\n",
        "## Xenia Snaphunt\n",
        "* greet\n",
        "  - utter_greet\n",
        "* Xenia_Snaphunt\n",
        "  - utter_Xenia_Snaphunt\n",
        "  - utter_more_info\n",
        "* affirm\n",
        "  - utter_happy\n",
        "\n",
        "## Xenia Xenatus\n",
        "* greet\n",
        "  - utter_greet\n",
        "* Xenia_Xenatus\n",
        "  - utter_Xenia_Xenatus\n",
        "  - utter_more_info\n",
        "* affirm\n",
        "  - utter_happy\n",
        "\n",
        "## Xenia GameZone\n",
        "* greet\n",
        "  - utter_greet\n",
        "* Xenia_Game\n",
        "  - utter_Xenia_Game\n",
        "  - utter_more_info\n",
        "* affirm\n",
        "  - utter_happy\n",
        "\n",
        "## Xenia Gab\n",
        "* greet\n",
        "  - utter_greet\n",
        "* Xenia_Gab\n",
        "  - utter_Xenia_Gab\n",
        "  - utter_more_info\n",
        "* affirm\n",
        "  - utter_happy\n",
        "\n",
        "## Xenia Shark\n",
        "* greet\n",
        "  - utter_greet\n",
        "* Xenia_Shark\n",
        "  - utter_Xenia_Shark\n",
        "  - utter_more_info\n",
        "* affirm\n",
        "  - utter_happy\n",
        "\n",
        "## Xenia CouchPotato\n",
        "* greet\n",
        "  - utter_greet\n",
        "* Xenia_Couch\n",
        "  - utter_Xenia_Couch\n",
        "  - utter_more_info\n",
        "* affirm\n",
        "  - utter_happy\n",
        "\n",
        "## Xenia DreamTeam\n",
        "* greet\n",
        "  - utter_greet\n",
        "* Xenia_Dream\n",
        "  - utter_Xenia_Dream\n",
        "  - utter_more_info\n",
        "* affirm\n",
        "  - utter_happy\n",
        "\n",
        "## Xenia Campus\n",
        "* greet\n",
        "  - utter_greet\n",
        "* Xenia_Campus\n",
        "  - utter_Xenia_Campus\n",
        "  - utter_more_info\n",
        "* affirm\n",
        "  - utter_happy\n",
        "\n",
        "## pcsb Xenia\n",
        "* greet\n",
        "  - utter_greet\n",
        "*pcsb_Xenia\n",
        "  - utter_pcsb_Xenia\n",
        "* affirm\n",
        "  - utter_happy\n",
        "\n",
        "## pcsb events\n",
        "* greet\n",
        "  - utter_greet\n",
        "* pcsb_events\n",
        "  - utter_pcsb_events\n",
        "  - utter_more_info\n",
        "\n",
        "## pcsb perks\n",
        "* greet\n",
        "  - utter_greet\n",
        "* pcsb_perks\n",
        "  - utter_pcsb_perks\n",
        "\n",
        "\n",
        "## happy path\n",
        "* greet\n",
        "  - utter_greet\n",
        "* mood_great\n",
        "  - utter_happy\n",
        "\n",
        "## sad path 1\n",
        "* greet\n",
        "  - utter_greet\n",
        "* mood_unhappy\n",
        "  - utter_cheer_up\n",
        "  - utter_did_that_help\n",
        "* affirm\n",
        "  - utter_happy\n",
        "\n",
        "## sad path 2\n",
        "* greet\n",
        "  - utter_greet\n",
        "* mood_unhappy\n",
        "  - utter_cheer_up\n",
        "  - utter_did_that_help\n",
        "* deny\n",
        "  - utter_goodbye\n",
        "\n",
        "## say goodbye\n",
        "* goodbye\n",
        "  - utter_goodbye\n",
        "\n",
        "## bot challenge\n",
        "* bot_challenge\n",
        "  - utter_iamabot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting data/stories.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SF4meuXlj3Qu",
        "outputId": "3c6668fe-f8b7-4379-c2c2-a627b741828a"
      },
      "source": [
        "model_path = rasa.train(domain,config, [training_files], output)\n",
        "print(model_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processed Story Blocks:   0%|          | 0/26 [00:00<?, ?it/s, # trackers=1]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94mTraining Core model...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processed Story Blocks: 100%|██████████| 26/26 [00:00<00:00, 253.13it/s, # trackers=1]\n",
            "Processed Story Blocks: 100%|██████████| 26/26 [00:00<00:00, 115.70it/s, # trackers=26]\n",
            "Processed Story Blocks: 100%|██████████| 26/26 [00:00<00:00, 105.04it/s, # trackers=24]\n",
            "Processed Story Blocks: 100%|██████████| 26/26 [00:00<00:00, 94.93it/s, # trackers=29]\n",
            "Processed trackers: 100%|██████████| 26/26 [00:00<00:00, 60.33it/s, # actions=113]\n",
            "Processed actions: 113it [00:00, 444.87it/s, # examples=113]\n",
            "Processed trackers: 100%|██████████| 526/526 [00:21<00:00, 24.89it/s, # actions=467]\n",
            "Epochs:   0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/rasa/utils/tensorflow/model_data.py:386: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  final_data[k].append(np.concatenate(np.array(v)))\n",
            "Epochs: 100%|██████████| 100/100 [01:21<00:00,  1.23it/s, t_loss=0.142, loss=0.006, acc=1.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94mCore model training completed.\u001b[0m\n",
            "\u001b[94mTraining NLU model...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[93m/usr/local/lib/python3.7/dist-packages/rasa/utils/common.py:363: UserWarning: You specified 'DIET' to train entities, but no entities are present in the training data. Skip training of entities.\n",
            "Epochs:   0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/rasa/utils/tensorflow/model_data.py:386: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  final_data[k].append(np.concatenate(np.array(v)))\n",
            "Epochs: 100%|██████████| 100/100 [00:13<00:00,  7.19it/s, t_loss=3.030, i_loss=1.294, i_acc=0.985]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94mNLU model training completed.\u001b[0m\n",
            "\u001b[92mYour Rasa model is trained and saved at '/content/test_project/models/20211025-135017.tar.gz'.\u001b[0m\n",
            "models/20211025-135017.tar.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hje2m4t-pYZd",
        "outputId": "445e5f95-e1ba-4e97-b398-2d0b1657f9b3"
      },
      "source": [
        "endpoints = 'endpoints.yml'\n",
        "chat(model_path, endpoints)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your bot is ready to talk! Type your messages here or send '/stop'.\n",
            "hi\n",
            "\u001b[92mHey! How are you?\u001b[0m\n",
            "fine\n",
            "\u001b[92mGreat, carry on!\u001b[0m\n",
            "tell me about pcsb\n",
            "\u001b[92mPICT CSI Student Branch, working under CSI, was established in 2016 to facilitate research, knowlwdge, and career enhancement for the students and inspire and nurture new entrants into the industry.\n",
            "It provides a platform for technical and non-technical education.\n",
            "One of our key strengths at PCSB is our rate of growthin a short span of time.\n",
            "We take pride in that we are one of the best student communities in Pune, still growing exponentially.\u001b[0m\n",
            "perks\n",
            "\u001b[92mPCSB is one of the most lively and innovative clubs at PICT.\n",
            "There are numerous perks to joining thr club. You will find a community of like minded, driven individuals\n",
            "who will give you opportunities and encouragement to acheve more.\n",
            "You can find people from all domains here such as Web dev, app dev and non technical domains like design and content.\u001b[0m\n",
            "events\n",
            "\u001b[92mPCSB conducts numerous events in a year.\n",
            "Some of them are:\n",
            "\t1. Xenia: The flagship event.\n",
            "\t2. Special Interest Groups.\n",
            "\t3. Panel Interviews.\n",
            "\t4. Domain Introduction.\n",
            "and many more.\u001b[0m\n",
            "\u001b[92mFor for more info visit PCSB [Xenia website](https://pcsbxenia.com/).\u001b[0m\n",
            "sigs\n",
            "\u001b[92mPCSB conducts multiple sigs throughout the year such as c++ and python.\u001b[0m\n",
            "xenia\n",
            "\u001b[92mXenia is the annual technical fiesta organized by PCSB.\n",
            "It includes 8 technical and 8 non technical events.\n",
            "\tA. Technical events:\n",
            "\t 1. Codestrike\n",
            "\t 2. Ninja Coding\n",
            "\t 3. Design Mastro\n",
            "\t 4. MineCraft Build Battles\n",
            "\t 5. Xenathon\n",
            "\t 6. Circuitron\n",
            "\t 7. Innoveiren\n",
            "\t 8. Data Cup\n",
            "\tB. Non technical events:\n",
            "\t 1. Campus to Corporate\n",
            "\t 2. SnapHunt\n",
            "\t 3. The Gift of Gab\n",
            "\t 4. Game Zone\n",
            "\t 5. Dream Team\n",
            "\t 6. Shark Tank\n",
            "\t 7. Couch Potato\n",
            "\t 8. Xenatus\n",
            "Do you want me to elaborate on any of the event?\u001b[0m\n",
            "codestrike\n",
            "\u001b[92mCodestrike is a competitive programming contest hosted online.\n",
            "Rules:\n",
            "\t1. Programmers can choose any language of their choice.\n",
            "\t2. The duration of the event is 2 hours.\n",
            "\t3. It is an individual event.\u001b[0m\n",
            "\u001b[92mFor for more info visit PCSB [Xenia website](https://pcsbxenia.com/).\u001b[0m\n",
            "ok\n",
            "\u001b[92mGreat, carry on!\u001b[0m\n",
            "no thanks\n",
            "\u001b[92mBye\u001b[0m\n",
            "/stop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOU7LopauUIp"
      },
      "source": [
        "# New section"
      ]
    }
  ]
}